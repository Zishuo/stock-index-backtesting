{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import os\n",
    "import time\n",
    "\n",
    "def fetch_stock_data_to_csv(ticker_list_file:str, ticker_output_path:str, ticker_err_list_file:str, max_ticker_retreival:int=100000):\n",
    "    ticker_list = pd.read_csv(ticker_list_file)\n",
    "    #create the output directory if it does not exist\n",
    "    if not os.path.exists(ticker_output_path):\n",
    "        os.mkdir(ticker_output_path)\n",
    "    #create the error list file if it does not exist\n",
    "    if not os.path.exists(ticker_err_list_file):\n",
    "        ticker_err_list = pd.DataFrame(columns=['Symbol','Error'])\n",
    "        ticker_err_list.to_csv(ticker_err_list_file)\n",
    "    else:\n",
    "        ticker_err_list = pd.read_csv(ticker_err_list_file)\n",
    "    #remove symobols has more than 4 letters\n",
    "    ticker_list = ticker_list[ticker_list['Symbol'].str.len()<=4]\n",
    "    ticker_list = ticker_list[ticker_list['Name'].str.contains('preferred',case=False)==False]\n",
    "    #change symbol ^ to - for yahoo finance\n",
    "    ticker_list['Symbol'] = ticker_list['Symbol'].str.replace('^','-')\n",
    "    ticker_list['Symbol'] = ticker_list['Symbol'].str.replace('/','-')\n",
    "\n",
    "    downloaded = 0\n",
    "    err_cnt = 0\n",
    "    suc = 0\n",
    "    #iterate through the list of tickers and download the data, limit the number of tickers to download to 100000\n",
    "    for row in ticker_list.iterrows():\n",
    "        if suc >= max_ticker_retreival:\n",
    "            print('{}/{} Reached max ticker retreival '.format(suc,max_ticker_retreival))\n",
    "            break\n",
    "        #check if we already downlaoded the data,if not then download it\n",
    "        if os.path.exists('{}/{}.csv'.format(ticker_output_path,row[1]['Symbol'])):                   #if the ticker is longer than 4 characters then del it\n",
    "            downloaded += 1\n",
    "            print('{}/{} Already  downloaded {}/{}'.format(suc,max_ticker_retreival,ticker_output_path,row[1]['Symbol']))\n",
    "            continue\n",
    "        elif ticker_err_list[ticker_err_list['Symbol']==row[1]['Symbol']].empty == False:\n",
    "            print('{}/{} Already  error      {}/{}'.format(suc,max_ticker_retreival,ticker_output_path,row[1]['Symbol']))\n",
    "        else:   \n",
    "            time.sleep(1)    \n",
    "            try:\n",
    "                #measure time to download data\n",
    "                start = time.time()\n",
    "                data = yf.download(row[1]['Symbol'])\n",
    "                end = time.time()\n",
    "                \n",
    "            except:\n",
    "                #use pd.concat to append to the dataframe\n",
    "                ticker_err_list = pd.concat([ticker_err_list,pd.DataFrame({'Symbol':[row[1]['Symbol']],'Error':['Error downloading data']})])\n",
    "                print('{}/{} Error downloading data for {}'.format(suc,max_ticker_retreival,row[1]['Symbol']))\n",
    "                err_cnt += 1\n",
    "                continue\n",
    "            if(data.empty):\n",
    "                #use pd.concat to append to the dataframe\n",
    "                ticker_err_list = pd.concat([ticker_err_list,pd.DataFrame({'Symbol':[row[1]['Symbol']],'Error':['No data']})])\n",
    "                err_cnt += 1\n",
    "                print('{}/{} No data for {}/{}'.format(suc,max_ticker_retreival, ticker_output_path,row[1]['Symbol']))\n",
    "                continue\n",
    "            data.to_csv('{}/{}.csv'.format(ticker_output_path,row[1]['Symbol']))\n",
    "            suc += 1\n",
    "            print('{}/{} Downloaded:{}s '.format(suc,max_ticker_retreival,row[1]['Symbol'],end-start,data.size))\n",
    "    ticker_err_list.to_csv(ticker_err_list_file)\n",
    "    print('Downloaded {} checked {} errors {}'.format(suc,downloaded,err_cnt))\n",
    "\n",
    "def stock_data_filter(ticker_list_file:str, ticker_output_path:str):\n",
    "    ticker_list = pd.read_csv(ticker_list_file)\n",
    "    removed = 0\n",
    "    for row in ticker_list.iterrows():\n",
    "        if os.path.exists('{}/{}.csv'.format(ticker_output_path,row[1]['Symbol'])) and len(row[1]['Symbol']) > 4:\n",
    "            os.remove('{}/{}.csv'.format(ticker_output_path,row[1]['Symbol']))\n",
    "            removed += 1\n",
    "        if os.path.exists('{}/{}.csv'.format(ticker_output_path,row[1]['Symbol'])) and row[1]['Name'].find('preferred') != -1:\n",
    "            os.remove('{}/{}.csv'.format(ticker_output_path,row[1]['Symbol']))\n",
    "            removed += 1\n",
    "    print('Removed {} tickers'.format(removed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the data for AMEX\n",
    "fetch_stock_data_to_csv('data/AMEX-TICKER-LIST-20230306.csv','data/AMEX','data/AMEX-TICKER-ERR-LIST-20230306.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the data for NASDAQ\n",
    "fetch_stock_data_to_csv('data/NASDAQ-TICKER-LIST-20230306.csv','data/NASDAQ', 'data/NASDAQ-TICKER-ERR-LIST-20230306.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the data for NYSE\n",
    "fetch_stock_data_to_csv('data/NYSE-TICKER-LIST-20230307.csv', 'data/NYSE', 'data/NYSE-TICKER-ERR-LIST-20230307.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data_filter('data/NASDAQ-TICKER-LIST-20230306.csv','data/NASDAQ')\n",
    "stock_data_filter('data/AMEX-TICKER-LIST-20230306.csv','data/AMEX')\n",
    "stock_data_filter('data/NYSE-TICKER-LIST-20230307.csv','data/NYSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "import pandas as pd\n",
    "def put_data_into_db(exchange:str, conn:sqlite3.Connection):\n",
    "    #iterate through the csv files and load the data into the database\n",
    "    for file in os.listdir('data/{}'.format(exchange)):\n",
    "        if file.endswith('.csv'):\n",
    "            print(exchange,'/',file, flush=True)\n",
    "            #read the csv file\n",
    "            df = pd.read_csv('data/{}/{}'.format(exchange,file))\n",
    "            df['Ticker'] = file[:-4]\n",
    "            df['Exchange'] = exchange\n",
    "            #convert the Date column to datetime\n",
    "            #df['Date'] = pd.to_datetime(df['Date'])\n",
    "            #set the Date and Ticker as the index\n",
    "            df.set_index(['Date','Ticker'],inplace=True)\n",
    "            df['MA200'] = df['Close'].rolling(200).mean()\n",
    "            df['MA50'] = df['Close'].rolling(50).mean()\n",
    "            df['MA20'] = df['Close'].rolling(20).mean()\n",
    "            df['MA10'] = df['Close'].rolling(10).mean()\n",
    "            df['MA5'] = df['Close'].rolling(5).mean()\n",
    "            #insert to table with distinct key if duplicate overwrite\n",
    "            print(df.head(1))\n",
    "            for(index, row) in df.iterrows():\n",
    "                conn.execute(\"REPLACE INTO stock_history (Date,Ticker,Open,High,Low,Close,'Adj Close',Volume,Exchange,MA200,MA50,MA20,MA10,MA5) VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?)\", (index[0],index[1],row['Open'],row['High'],row['Low'],row['Close'],row['Adj Close'],row['Volume'],row['Exchange'],row['MA200'],row['MA50'],row['MA20'],row['MA10'],row['MA5']))\n",
    "            conn.commit()\n",
    "    conn.execute(\"VACUUM\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the database\n",
    "conn = sqlite3.connect('data/stock_data.db')\n",
    "#create the table if not exists\n",
    "conn.execute('''CREATE TABLE IF NOT EXISTS stock_history(Date DATE NOT NULL,Ticker TEXT NOT NULL,Open REAL,High REAL,Low REAL,Close REAL,'Adj Close' REAL,Volume REAL,Exchange TEXT NOT NULL,MA200 REAL,MA50 REAL,MA20 REAL,MA10 REAL,MA5 REAL,PRIMARY KEY (Date,Ticker))''')\n",
    "conn.commit()\n",
    "#print the column names of the table\n",
    "print(pd.read_sql_query(\"SELECT * FROM sqlite_master WHERE type='table'\", conn))\n",
    "#query table column names and keys and infos.\n",
    "print(pd.read_sql_query(\"PRAGMA table_info(stock_history)\", conn))\n",
    "#put the data into the database\n",
    "put_data_into_db('NASDAQ',conn)\n",
    "put_data_into_db('AMEX',conn)\n",
    "put_data_into_db('NYSE',conn)\n",
    "\n",
    "\n",
    "#close the connection\n",
    "conn.close()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test db sample pulling data from the database\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect('data/stock_data.db')\n",
    "#conn.execute('''CREATE TABLE IF NOT EXISTS stock_history(Date DATE NOT NULL,Ticker TEXT NOT NULL,Open REAL,High REAL,Low REAL,Close REAL,'Adj Close' REAL,Volume REAL,Exchange TEXT NOT NULL,SMA200 REAL,SMA50 REAL,SMA20 REAL,SMA10 REAL,SMA5 REAL,PRIMARY KEY (Date,Ticker))''')\n",
    "#conn.commit()\n",
    "#print the column names of the table\n",
    "print(pd.read_sql_query(\"SELECT * FROM sqlite_master WHERE type='table'\", conn))\n",
    "#query table column names and keys and infos.\n",
    "print(pd.read_sql_query(\"PRAGMA table_info(stock_history)\", conn))\n",
    "#read the 1000 line data from the table\n",
    "df = pd.read_sql_query(\"SELECT * FROM stock_history Where Ticker='ACLS' limit 100\", conn)\n",
    "#count total entries in the db\n",
    "print(pd.read_sql_query(\"SELECT COUNT(*) FROM stock_history\", conn))\n",
    "#print the first 5 rows of the data\n",
    "print(df.head(5))\n",
    "#df.to_csv('ACLS_export.csv',index=False)\n",
    "#close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test db data\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect('data/stock_data.db')\n",
    "#conn.execute('''CREATE TABLE IF NOT EXISTS stock_history(Date DATE NOT NULL,Ticker TEXT NOT NULL,Open REAL,High REAL,Low REAL,Close REAL,'Adj Close' REAL,Volume REAL,Exchange TEXT NOT NULL,SMA200 REAL,SMA50 REAL,SMA20 REAL,SMA10 REAL,SMA5 REAL,PRIMARY KEY (Date,Ticker))''')\n",
    "#df = pd.read_csv('ACLS_export.csv')\n",
    "df = pd.read_sql_query(\"SELECT * FROM stock_history Where Ticker='A' limit 100000\", conn)\n",
    "#df['Date'] = pd.to_datetime(df['Date'])\n",
    "#set the Date and Ticker as the index\n",
    "df.set_index(['Date','Ticker'],inplace=True)\n",
    "#remove duplicate index\n",
    "#print(df.count())\n",
    "#df = df[~df.index.duplicated(keep='first')]\n",
    "print(df.count())\n",
    "print(df.head(5))\n",
    "\n",
    "#df.to_sql('stock_history', conn, if_exists='replace')\n",
    "#for(index, row) in df.iterrows():\n",
    "#    conn.execute(\"REPLACE INTO stock_history (Date,Ticker,Open,High,Low,Close,'Adj Close',Volume,Exchange,SMA200,SMA50,SMA20,SMA10,SMA5) VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?)\", (index[0],index[1],row['Open'],row['High'],row['Low'],row['Close'],row['Adj Close'],row['Volume'],row['Exchange'],row['SMA200'],row['SMA50'],row['SMA20'],row['SMA10'],row['SMA5']))\n",
    "#conn.commit()\n",
    "#conn.execute(\"VACUUM\")\n",
    "conn.close()\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
