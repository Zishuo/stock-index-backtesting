{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import os\n",
    "import time\n",
    "\n",
    "def fetch_stock_data_to_csv(ticker_list_file:str, ticker_output_path:str, ticker_err_list_file:str, max_ticker_retreival:int=100000):\n",
    "    ticker_list = pd.read_csv(ticker_list_file)\n",
    "    #create the output directory if it does not exist\n",
    "    if not os.path.exists(ticker_output_path):\n",
    "        os.mkdir(ticker_output_path)\n",
    "    #create the error list file if it does not exist\n",
    "    if not os.path.exists(ticker_err_list_file):\n",
    "        ticker_err_list = pd.DataFrame(columns=['Symbol','Error'])\n",
    "        ticker_err_list.to_csv(ticker_err_list_file)\n",
    "    else:\n",
    "        ticker_err_list = pd.read_csv(ticker_err_list_file)\n",
    "\n",
    "    #change symbol ^ to - for yahoo finance\n",
    "    ticker_list['Symbol'] = ticker_list['Symbol'].str.replace('^','-')\n",
    "    ticker_list['Symbol'] = ticker_list['Symbol'].str.replace('/','-')\n",
    "\n",
    "    downloaded = 0\n",
    "    err_cnt = 0\n",
    "    suc = 0\n",
    "    #iterate through the list of tickers and download the data, limit the number of tickers to download to 100000\n",
    "    for row in ticker_list.iterrows():\n",
    "        if suc >= max_ticker_retreival:\n",
    "            print('{}/{} Reached max ticker retreival '.format(suc,max_ticker_retreival))\n",
    "            break\n",
    "        #check if we already downlaoded the data,if not then download it\n",
    "        if os.path.exists('{}/{}.csv'.format(ticker_output_path,row[1]['Symbol'])):\n",
    "            downloaded += 1\n",
    "            print('{}/{} Already  downloaded {}/{}'.format(suc,max_ticker_retreival,ticker_output_path,row[1]['Symbol']))\n",
    "            continue\n",
    "        elif ticker_err_list[ticker_err_list['Symbol']==row[1]['Symbol']].empty == False:\n",
    "            print('{}/{} Already  error      {}/{}'.format(suc,max_ticker_retreival,ticker_output_path,row[1]['Symbol']))\n",
    "        else:   \n",
    "            time.sleep(1)    \n",
    "            try:\n",
    "                #measure time to download data\n",
    "                start = time.time()\n",
    "                data = yf.download(row[1]['Symbol'])\n",
    "                end = time.time()\n",
    "                \n",
    "            except:\n",
    "                #use pd.concat to append to the dataframe\n",
    "                ticker_err_list = pd.concat([ticker_err_list,pd.DataFrame({'Symbol':[row[1]['Symbol']],'Error':['Error downloading data']})])\n",
    "                print('{}/{} Error downloading data for {}'.format(suc,max_ticker_retreival,row[1]['Symbol']))\n",
    "                err_cnt += 1\n",
    "                continue\n",
    "            if(data.empty):\n",
    "                #use pd.concat to append to the dataframe\n",
    "                ticker_err_list = pd.concat([ticker_err_list,pd.DataFrame({'Symbol':[row[1]['Symbol']],'Error':['No data']})])\n",
    "                err_cnt += 1\n",
    "                print('{}/{} No data for {}/{}'.format(suc,max_ticker_retreival, ticker_output_path,row[1]['Symbol']))\n",
    "                continue\n",
    "            data.to_csv('{}/{}.csv'.format(ticker_output_path,row[1]['Symbol']))\n",
    "            suc += 1\n",
    "            print('{}/{} Downloaded:{}s '.format(suc,max_ticker_retreival,row[1]['Symbol'],end-start,data.size))\n",
    "    ticker_err_list.to_csv(ticker_err_list_file)\n",
    "    print('Downloaded {} checked {} errors {}'.format(suc,downloaded,err_cnt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the data for AMEX\n",
    "fetch_stock_data_to_csv('data/AMEX-TICKER-LIST-20230306.csv','data/AMEX','data/AMEX-TICKER-ERR-LIST-20230306.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the data for NASDAQ\n",
    "fetch_stock_data_to_csv('data/NASDAQ-TICKER-LIST-20230306.csv','data/NASDAQ', 'data/NASDAQ-TICKER-ERR-LIST-20230306.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_stock_data_to_csv('data/NYSE-TICKER-LIST-20230307.csv', 'data/NYSE', 'data/NYSE-TICKER-ERR-LIST-20230307.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BA</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [AI, BA]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the data from txt file to dictionary\n",
    "import pandas as pd\n",
    "#load the data from txt file to dictionary\n",
    "#sample {'AI':  'C3.ai,  Inc.',  'BA':  'Boeing  Company  (The)'}\n",
    "\n",
    "with open('data/tmp.txt', 'r') as f:\n",
    "    contents = f.read()\n",
    "    data_dict = eval(contents)\n",
    "#convert the dictionary to dataframe\n",
    "data_df = pd.DataFrame.from_dict(data_dict, orient='index', columns=['Name'])\n",
    "#drop the 'Name' column\n",
    "data_df = data_df.drop(columns=['Name'])\n",
    "data_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "import pandas as pd\n",
    "def put_data_into_db(exchange:str, conn:sqlite3.Connection):\n",
    "    #iterate through the csv files and load the data into the database\n",
    "    for file in os.listdir('data/{}'.format(exchange)):\n",
    "        if file.endswith('.csv'):\n",
    "            print(exchange,'/',file, flush=True)\n",
    "            #read the csv file\n",
    "            df = pd.read_csv('data/{}/{}'.format(exchange,file))\n",
    "            df['Ticker'] = file[:-4]\n",
    "            df['Exchange'] = exchange\n",
    "            #convert the Date column to datetime\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            #set the Date and Ticker as the index\n",
    "            df.set_index(['Date','Ticker'],inplace=True)\n",
    "            #load the data into the database\n",
    "            df.to_sql('stock_history',conn,if_exists='append')\n",
    "            conn.commit()\n",
    "    conn.execute(\"VACUUM\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the database\n",
    "conn = sqlite3.connect('data/stock_data.db')\n",
    "#create the table if not exists\n",
    "conn.execute('''CREATE TABLE IF NOT EXISTS stock_history\n",
    "            (Date DATE NOT NULL,\n",
    "            Ticker TEXT NOT NULL,\n",
    "            Open REAL,\n",
    "            High REAL,\n",
    "            Low REAL,\n",
    "            Close REAL,\n",
    "            'Adj Close' REAL,\n",
    "            Volume REAL,\n",
    "            Exchange TEXT NOT NULL,\n",
    "            PRIMARY KEY (Date,Ticker));''')\n",
    "conn.commit()\n",
    "\n",
    "#put the data into the database\n",
    "\n",
    "put_data_into_db('AMEX',conn)\n",
    "put_data_into_db('NYSE',conn)\n",
    "put_data_into_db('NASDAQ',conn)\n",
    "\n",
    "#close the connection\n",
    "conn.close()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample pulling data from the database\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect('data/stock_data.db')\n",
    "\n",
    "#print the column names of the table\n",
    "print(pd.read_sql_query(\"SELECT * FROM sqlite_master WHERE type='table'\", conn))\n",
    "#read the 1000 line data from the table\n",
    "df = pd.read_sql_query(\"SELECT * FROM stock_history Where Ticker='ACLS' limit 100000\", conn)\n",
    "#print the first 5 rows of the data\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "print(df.tail(10))\n",
    "#close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
